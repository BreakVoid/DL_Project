% Use only LaTeX2e, calling the article.cls class and 12-point type.

\documentclass[12pt]{article}

% Users of the {thebibliography} environment or BibTeX should use the
% scicite.sty package, downloadable from *Science* at
% www.sciencemag.org/about/authors/prep/TeX_help/ .
% This package should properly format in-text
% reference calls and reference-list numbers.

\usepackage{scicite}

% Use times if you have the font installed; otherwise, comment out the
% following line.

\usepackage{times}

% The preamble here sets up a lot of new/revised commands and
% environments.  It's annoying, but please do *not* try to strip these
% out into a separate .sty file (which could lead to the loss of some
% information when we convert the file to other formats).  Instead, keep
% them in the preamble of your main LaTeX source file.


% The following parameters seem to provide a reasonable page setup.

\topmargin 0.0cm
\oddsidemargin 0.2cm
\textwidth 16cm 
\textheight 21cm
\footskip 1.0cm


%The next command sets up an environment for the abstract to your paper.

\newenvironment{sciabstract}{%
\begin{quote} \bf}
{\end{quote}}


% If your reference list includes text notes as well as references,
% include the following line; otherwise, comment it out.

\renewcommand\refname{References and Notes}

% The following lines set up an environment for the last note in the
% reference list, which commonly includes acknowledgments of funding,
% help, etc.  It's intended for users of BibTeX or the {thebibliography}
% environment.  Users who are hand-coding their references at the end
% using a list environment such as {enumerate} can simply add another
% item at the end, and it will be numbered automatically.

\newcounter{lastnote}
\newenvironment{scilastnote}{%
\setcounter{lastnote}{\value{enumiv}}%
\addtocounter{lastnote}{+1}%
\begin{list}%
{\arabic{lastnote}.}
{\setlength{\leftmargin}{.22in}}
{\setlength{\labelsep}{.5em}}}
{\end{list}}


% Include your paper's title here

\title{{\bf Deep Learning Course Assignment Report}} 


% Place the author information here.  Please hand-code the contact
% information and notecalls; do *not* use \footnote commands.  Let the
% author contact information appear immediately below the author names
% as shown.  We would also prefer that you don't change the type-size
% settings shown here.

\author
{{\it Bicheng Gao,$^{1}$ Songyu Ke,$^{2}$ Yuhao Zhou$^{3}$}\\
\\
\normalsize{{\it $^{1}$volz.kz.g@gmail.com}}\\
\normalsize{{\it $^{2}$songyuke@sjtu.edu.cn}}\\
\normalsize{{\it $^{3}$yuhao\_zhou95@sjtu.edu.cn}}\\
\\
\normalsize{{\it 14 ACM class, Shanghai Jiao Tong University}}
}

% Include the date command, but leave its argument blank.

\date{}



%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%



\begin{document} 

% Double-space the manuscript.

\baselineskip24pt

% Make the title.

\maketitle 



% Place your abstract within the special {sciabstract} environment.

\begin{sciabstract}
{\bf ABSTRACT\/ ******edit(accuracy)} \\
The purpose of this research is to classify the tone using the neural network and compare the differences between three neural network frameworks --- \texttt{Torch}, \texttt{MXNet} and \texttt{Theano}. Since it seems hard for the neural network to extract the feature from raw data automatically, it is necessary to preprocess the data with some proper methods. We've tried two ways of data preprocessing: eliminating the noise in all datasets or add some noise in training data to fit the environment of test data. With the processing data and Convolutional Neural Networks, we finally achieved the accuracy of {\_\_\_\_\_\_\_\_\%} in \texttt{test\_new} dataset. After reaching a better performance, we keep working on comparing the frameworks and provide some major factors listing on this report.
\end{sciabstract}

% In setting up this template for *Science* papers, we've used both
% the \section* command and the \paragraph* command for topical
% divisions.  Which you use will of course depend on the type of paper
% you're writing.  Review Articles tend to have displayed headings, for
% which \section* is more appropriate; Research Articles, when they have
% formal topical divisions at all, tend to signal them with bold text
% that runs into the paragraph, for which \paragraph* is the right
% choice.  Either way, use the asterisk (*) modifier, as shown, to
% suppress numbering.

\section{Introduction ******edit}

The project of {\it Deep Learning Course} aims at constructing a proper neural network model to solve tone classification with different frameworks and discuss factors which may have an influence on the performance of each framework.\\
\\
With only the raw data, the file: \texttt{train.engy}, \  \texttt{train.f0}, \ \texttt{test.engy}, \ \texttt{test.f0},  \ \texttt{test\_new.engy}, \ \texttt{text\_new.f0}, it's a rather tough task for neural network itself to extract proper feature that may have a good performance in the test dataset. Therefore, preprocessing the data  is an appropriate way to change the data, which is much easier to train a better network. We eliminate the low energy noise and use cubic spline interpolation to fix the data with a proper length. Then with those data (in directory \texttt{data}) {\bf ****edit(data processing procedure)}\\
Since the test data is recording in the noisy environment, which is totally different from the situation of training data, the other thought is to add some white noise in the training data to fit the environment of the test data. We also tried this method to evaluate the performance.\\
And in the {\it $2^{nd}$ Section}, we will provide all the details in our data preprocessing.\\
\\
After preprocessing the data, another major work need to be decided is the model of neural networks. With different frameworks, the implementation of each framework is different. Therefore, with the same parameters, the performance of three frameworks may have some slight changes. To choose an appropriate neural network model is complicated in many works. In this project, the total size of training data set is 400 with the fixed data shape: [$120, 1$] ([width, height]). Therefore a small model may work in a small collection of data. Fully-connected Networks and Convolutional Neural Networks are our choices, since it has excellent performance in many tasks. Meanwhile, we also try some complicated models with more layers, and the results of models comparison are also shown in the report.\\
All the information details of this part is shown in the {\it $3^{rd}$ Section} {\bf Model of Neural Networks}\\
\\
In the {\it $4^{th}$ Section} {\bf Background of the Frameworks}, we will provide the elementary information of three frameworks: \texttt{Torch}, \texttt{Theano}, \texttt{MXNet}. We will first give out a fundamental analysis of three frameworks through their own description and then compare with our own evaluations by the experiment of the tone classification in some aspects, which shown in the {\it $5^{th}$ Section} {\bf Evaluation}. {\bf ******edit(some factors, reason)}\\
\\
For the {\it $6^{th}$ Section} {\bf Future Work} Part, we're going to show some vulnerabilities of our works and the improvement that can be implemented in the future, and giving a {\bf conclusion} in the {\it $7^{th}$ Section}.  {\bf ****** edit (some detail future work lists)}
\\

\section{Data Preprocessing}{\bf **** edit }

\section{Model of Neural Networks}
In this part, we're going to show some models we used to solve tone classification. During the data processing, we've changed some parameters and models to fit the data to have a good training performance. With all models we used, the following three models can be the most representative ones for our experiment. Some may performance out of expectation, and others may have no improvement compared with simple ones. The models we shown are as follows:
\begin{itemize}
	\item Three layers of Fully Connected Networks.
	\item Variant of the Lenet.
	\item Variant of VGG.
\end{itemize}
Three layers of Fully Connected Networks is the most simple model we used, and then improve it to the Lenet

\subsection{Three layers of Fully Connected Networks}

\subsection{Variant of the Lenet}

\subsection{Variant of VGG}

\subsection{Evalution *****edit}




\section{Background of the Frameworks}

We now keep working on the second major part of our {\it DL\_project}. Before we compare with the three models, we first list some standard information, from which we may derive inspiration of deciding the comparative factors.\\
Most of the background information are from their {\it Official Site}.

\subsection{\texttt{Torch}}
The summary of core features of Torch can be listed as follows:
\begin{itemize}
	\item a powerful N-dimensional array
	\item lots of routines for indexing, slicing, transposing, ...
	\item amazing interface to C, via LuaJIT
\end{itemize}
\subsection{\texttt{Theano}}

\subsection{\texttt{MXNet}}



\section{Evaluation ***** edit}
In this part, we're going to give a formal evaluation system for three frameworks --- \texttt{Torch}, \texttt{Theano}, \texttt{MXNet}. With the following aspects and the general idea to these frameworks, it is rational for us to give a brief impression and further analysis to the frameworks. And the factors we use are listed as follows:
\subsection{Learning and Implementation}

\subsection{Training Effect Evaluation}

\subsection{Training Time Evaluation}

\section{Future Work}
As we have spent most of dealing with the dataset, there're still many works need to be accomplished.
As for the model part, thought we've tried the several neural networks and choose {\it Three-layers Fully Connected Networks}, {\it Variant of Lenet} and {\it VGG} to represent most performance of our model, there're still many networks may work well, but we haven't tried yet.\\
Recurrent Neural Network performances well in many cases of Natural Language Processing in recent works. We guess it may also improve our model to some extent. And like Alex et al.,[14] work on Speech Recognition, RNNs may have a result out of expectation.\\
For three frameworks, there're still some problems remain to be solved. Just like MXNet, many researchers will suffer from its poor documents. Therefore, some of the effect or implementation of the embedded functions must be learnt from its open-source code. Meanwhile, MXNet has a well-performed encapsulation and module, therefore, their still many embedded functions is left to do some research. Maybe it can be another aspect for the framework evaluation.\\


\section{Conclusion}

\section{Reference}
[14] Alex Graves, Navdeep Jaitly, {\it Towards End-to-End Speech Recognition with Recurrent Neural Networks}


\end{document}




















